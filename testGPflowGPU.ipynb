{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 done\n",
      "iter 1 done\n",
      "iter 2 done\n",
      "iter 3 done\n",
      "iter 4 done\n",
      "iter 5 done\n",
      "iter 6 done\n",
      "iter 7 done\n",
      "iter 8 done\n",
      "iter 9 done\n",
      "iter 10 done\n",
      "iter 11 done\n",
      "iter 12 done\n",
      "iter 13 done\n",
      "iter 14 done\n",
      "iter 15 done\n",
      "iter 16 done\n",
      "iter 17 done\n",
      "iter 18 done\n",
      "iter 19 done\n",
      "iter 20 done\n",
      "iter 21 done\n",
      "iter 22 done\n",
      "iter 23 done\n",
      "iter 24 done\n",
      "iter 25 done\n",
      "iter 26 done\n",
      "iter 27 done\n",
      "iter 28 done\n",
      "iter 29 done\n",
      "iter 30 done\n",
      "iter 31 done\n",
      "iter 32 done\n",
      "iter 33 done\n",
      "iter 34 done\n",
      "iter 35 done\n",
      "iter 36 done\n",
      "iter 37 done\n",
      "iter 38 done\n",
      "iter 39 done\n",
      "iter 40 done\n",
      "iter 41 done\n",
      "iter 42 done\n",
      "iter 43 done\n",
      "iter 44 done\n",
      "iter 45 done\n",
      "iter 46 done\n",
      "iter 47 done\n",
      "iter 48 done\n",
      "iter 49 done\n",
      "iter 50 done\n",
      "iter 51 done\n",
      "iter 52 done\n",
      "iter 53 done\n",
      "iter 54 done\n",
      "iter 55 done\n",
      "iter 56 done\n",
      "iter 57 done\n",
      "iter 58 done\n",
      "iter 59 done\n",
      "iter 60 done\n",
      "iter 61 done\n",
      "iter 62 done\n",
      "iter 63 done\n",
      "iter 64 done\n",
      "iter 65 done\n",
      "iter 66 done\n",
      "iter 67 done\n",
      "iter 68 done\n",
      "iter 69 done\n",
      "iter 70 done\n",
      "iter 71 done\n",
      "iter 72 done\n",
      "iter 73 done\n",
      "iter 74 done\n",
      "iter 75 done\n",
      "iter 76 done\n",
      "iter 77 done\n",
      "iter 78 done\n",
      "iter 79 done\n",
      "iter 80 done\n",
      "iter 81 done\n",
      "iter 82 done\n",
      "iter 83 done\n",
      "iter 84 done\n",
      "iter 85 done\n",
      "iter 86 done\n",
      "iter 87 done\n",
      "iter 88 done\n",
      "iter 89 done\n",
      "iter 90 done\n",
      "iter 91 done\n",
      "iter 92 done\n",
      "iter 93 done\n",
      "iter 94 done\n",
      "iter 95 done\n",
      "iter 96 done\n",
      "iter 97 done\n",
      "iter 98 done\n",
      "iter 99 done\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'builtin_function_or_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39mn_iters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trained equivalent to a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m sample, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_iters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m iteration smc sampler, this was done in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mend\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'builtin_function_or_method'"
     ]
    }
   ],
   "source": [
    "import gpflow\n",
    "from gpflow.kernels import Matern52 as mt52\n",
    "import numpy as np\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "n_samples, n_iters = 100,100\n",
    "n_data_points = 200\n",
    "\n",
    "start = time.time()\n",
    "X_train = np.random.rand(n_data_points,2)\n",
    "y_train = np.random.rand(n_data_points,1)\n",
    "\n",
    "def gpflow_sample(sample):\n",
    "    variance = sample[:1][0]\n",
    "    lengths = (sample[1:])\n",
    "    kern = mt52(variance=variance, lengthscales=lengths)\n",
    "    model = gpflow.models.GPR(\n",
    "        (X_train, y_train),\n",
    "        kernel=kern)\n",
    "\n",
    "    mean, cov = model.predict_y(X_test, full_cov=False)\n",
    "    mean = np.squeeze(mean.numpy())\n",
    "    cov = np.squeeze(cov.numpy())\n",
    "\n",
    "    return 0\n",
    "\n",
    "start = time.time\n",
    "\n",
    "\n",
    "for i in range(n_iters):\n",
    "    X_test = np.random.rand(5,2)\n",
    "    samples = np.random.rand(n_samples, 3)\n",
    "    futures = [gpflow_sample(sample) for sample in samples]\n",
    "\n",
    "    print(f'iter {i} done')\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'{n_samples* n_iters} trained equivalent to a {n_samples} sample, {n_iters} iteration smc sampler, this was done in {end-start:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's definitely using gpu vram, but only 12% of the gpu might be able to multithread just point a join condition in each for loop, also doesn't seem to offloat the meme usage 17% at 200 data points instead of 20 - but basically the same speed for each iter, really just need to write a better proposal - also am curious to see the dif on normal windows vs - me trying to get it working on ubuntu with gpu usage - which i think is curr being used bc its quite hot (60C) idk tho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "outputs:\n",
    "* 10000 trained equivalent to a 100 sample, 100 iteration smc sampler, this was done in 323.0208 seconds - with GPU I think on 20 datapoints 5 test points\n",
    "* 10000 trained equivalent to a 100 sample, 100 iteration smc sampler, this was done in 350 seconds - with GPU I think on 200 datapoints 5 test points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
